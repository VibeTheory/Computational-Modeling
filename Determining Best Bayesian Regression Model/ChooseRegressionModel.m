% Bayesian regression problem

% In this program, we consider seven possible regression models. Our goal
% is to decide which one of the seven models is the "best" one to explain
% the observed data. For each model with specific parameters Beta,
% "goodness of fit" can be measured by the likelihood term P(y|Beta,M).
% Here, Beta is a vector of regression coefficients, and M indicates a
% polynomial regression model of order p. Model evidence is evaluated using
% P(y|M), which describes how likely the data are generated by a polynomial
% model.

clear all; close all;

load('InputQ2.mat')

orders = 0:6 ; % order of seven possible models that we consider

sx  = 5    ; % std dev in model predictions


%% A) Analyze goodness of fit of each model P(y|B,M)

% Define predictions of all possible polynomial regression models, given 
% the data and our specific model parameters b, and compute the likelihood 
% of observations for each model with specific parameters b

for iModel = 1:length(orders)  % for all 7 models

    beta = b(iModel,:) ;    % 1x7 vector of current model's B parameters [B(0) B(1) B(2) B(3) B(4) B(5) B(6)]

    for iObs = 1:length(x)  % for all 8 (data,obs.) pairs

        data  = x(iObs)         ; % each data point
        obs   = y(iObs)         ; % each observation

%       error = normrnd(0,sx^2) ; % error term for each model prediction 
%       (originally thought we had to calculate each prediction's error)

        xterms = (ones(1,length(orders)) * data) .^ orders ;       % 1x7 vector [x^0 x^1 x^2 x^3 x^4 x^5 x^6] 
                                                                   % x terms for current data 
        
        pred(iModel,iObs) = sum( beta .* xterms ) ; % + error  ;   % yhat = B(0) + B(1)x + B(2)x^2 + ... + B(p)x^p
                                                                   % 7x8 matrix (8 predictions for all 7 models)
    end

    likelihoodAll(iModel,:) = normpdf(y, pred(iModel,:), sx) ;     % 7x8 matrix: for each model, likelihood 
                                                                   % of each observation given each prediction
end
    
likelihood = prod(likelihoodAll,2) ; % 7x1 vec: take the product across observations for each model likelihood

normlikelihood = likelihood ./ sum(likelihood,1) ; % normalize model likelihoods

loglike = log(normlikelihood) ; % 7x1 vec: logarithm of each model likelihood


% Plot the log-likelihood against the seven possible models

categories = categorical({'p=0','p=1','p=2','p=3','p=4','p=5','p=6'}) ;

% figure('Name', 'Likelihoods')
% bar(categories, normlikelihood)
% title('Likelihood of Possible Polynomial Regression Models')
% xlabel('Model Order')
% ylabel('P(y|B,M)')

figure('Name', 'Log-Likelihoods')
plot(categories, loglike)
title('Log-Likelihood of Possible Polynomial Regression Models')
xlabel('Model Order')
ylabel('Log P(y|B,M)')

%saveas(gcf, 'Log-Likelihood.png')

%% B) Evaluate each model by its model evidence P(y|M)

% Model evidence is discretely approximated by the average goodness of fit
% among P(y|B,M) when summed over all possible sets of B values (or over a 
% number N of sampled sets of B values in our case)

N = 500 ; % sample number

% Sample N sets of B values for each model M according to the prior
% distribution (we assume the prior P(B) to be a uniform distribution)


for iModel = 1:length(orders)       % for all 7 models

    oldbetas = nonzeros(b(iModel,:))' ; % nonzero beta terms given for each model
    Alims = oldbetas - 0.5 ;
    Blims = oldbetas + 0.5 ;

    for iBeta = 1:length(oldbetas)  % for each given beta term per model

        for iSample = 1:N           % for 500 samples

            betaSample(iModel,iBeta, iSample) = unifrnd(Alims(iBeta), Blims(iBeta)) ; 
            % 7x7x500 mat: 500 sampled sets of Beta values for each model
        end
    end
end

% For each sample set B(j), compute P(y|B(j),M), given by the likelihood eq

% Reminder:
%   i = 1:7    models
%   j = 1:500  sample sets                     *betaSample = (i,k,j)
%   k = 1:p    beta values per sample set       7 rows x 7 cols x 500 pages

for iModel = 1:length(orders)  % for all 7 models

    for iBeta = 1:N            % for 500 samples

        beta = betaSample(iModel,:, iBeta) ;  % 1x7 vector of current model/sample's B parameters [B(0) B(1) B(2) B(3) B(4) B(5) B(6)]

        for iObs = 1:length(x)  % for all 8 (data,obs.) pairs

            data  = x(iObs)         ; % each data point
            obs   = y(iObs)         ; % each observation

%           error = normrnd(0,sx^2) ; % error term for each model prediction (unused)
    
            xterms = (ones(1,length(orders)) * data) .^ orders ;       % 1x7 vector [x^0 x^1 x^2 x^3 x^4 x^5 x^6] 
                                                                       % x terms for current data pt x(i)
            
            predB(iModel,iObs,iBeta) = sum( beta .* xterms )   ;       % yhat = B(0) + B(1)x + B(2)x^2 + ... + B(p)x^p
                                                                       % 7x8x500 matrix (8 predictions for all 7 models for 500 sets of B parameters)
        end

        modelpred = predB(iModel,:,iBeta) ; % predictions from current model/sample (for visibility)

        likelihoodAllObs(iModel,:, iBeta) = normpdf(y, modelpred, sx) ;   % 7x8x500 matrix: for each model, for each 
    end                                                                   % sampled set of parameters, the likelihood
end                                                                       % of each observation given each prediction  
        
likelihoodAllB = prod(likelihoodAllObs,2) ; % 7x1x500 mat: take the product across observations for each
                                            % model's likelihood for each sample set of parameters P(y|B(j),M)


% Average across all sampled sets of Beta parameters to approximate P(y|M)

likelihoodB = sum(likelihoodAllB,3) ./ N ; % 7x1 mat: model evidence P(y|M)

normlikelihoodB = likelihoodB ./ sum(likelihoodB,1) ; % normalized model evidence P(y|M)

logevidence = log(normlikelihoodB) ; % logarithm of model evidence


% Plot the model evidence against the seven possible models

categories = categorical({'p=0','p=1','p=2','p=3','p=4','p=5','p=6'}) ;

% figure('Name', 'Evidence')
% bar(categories, normlikelihoodB)
% title('Model Evidence of Possible Polynomial Regression Models')
% xlabel('Model Order')
% ylabel('P(y|M)')

figure('Name', 'Log-Evidence')
bar(categories, logevidence)
title('Log Model Evidence of Possible Polynomial Regression Models')
xlabel('Model Order')
ylabel('Log P(y|M)')

%saveas(gcf, 'Log-Model Evidence.png')


